---
title: "Fundamentals of Computing and Data Display"
subtitle: Assignment 2
output:
  html_document:
    df_print: paged
---

## Setup

install.packages("gtrendsR")
install.packages("censusapi")
```{r}
library(tidyverse)
library(gtrendsR)
library(censusapi)
```

## Google Trends

In this notebook, your task is to combine and explore web data using APIs and `dplyr`. Try to utilize piping in this notebook when writing your code.

Our first data source is the Google Trends API. This time we are interested in the search trends for `crime` and `loans` in Illinois in the year 2016.

```{r}
res <- gtrends(c("crime", "loans"), geo = "US-IL", time = "2016-01-01 2016-12-31", low_search_volume = TRUE)
plot(res)
```

The resulting list includes a `data.frame` with the search interest by city. Extract this data set as a `tibble` and print the first few observations.

```{r}

interest_city <- as_tibble(res$interest_by_city)

print(interest_city[1:5, ])

```

Find the mean, median and variance of the search hits for the keywords `crime` and `loans`. This can be done via piping with `dplyr`.

```{r}

interest_city %>%
  na.omit %>%
  group_by(keyword) %>%
  summarise(mean(hits), median(hits), var(hits))

```

Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city. Transform the `tibble` accordingly and save the result as a new object.

```{r}

new_interest_city <- 
  interest_city %>%
  group_by(location, keyword) %>%
  mutate(sum_hits = sum(hits)) %>%
  select(-("hits"))  %>%
  distinct %>%
  spread(key=keyword, value=sum_hits)

head(new_interest_city)

```

Which cities (locations) have the highest search frequency for `loans`? Print the first rows of the new `tibble` from the previous chunk, ordered by `loans`.

```{r}

new_interest_city_sorted <- 
  new_interest_city %>%
  arrange(desc(loans))

print(new_interest_city_sorted[1:5, ])

```

Is there a relationship between the search intensities between the two keywords we used? Create a scatterplot of `crime` and `loans` with `qplot()`.

```{r}

qplot(crime, loans, data = new_interest_city)

```
There appears to be a positive linear relationship between the search intensities between keywords 'crime' and 'loans', however many cities were not included due to missing values. This means that no conclusions can be made just from this visual and further analysis is required. 


## Google Trends + ACS

Now lets add another data set. The censusapi package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

https://api.census.gov/data/key_signup.html

Once you have an access key, store this key in the cs_key object. We will use this object in all following API queries.

```{r}
cs_key <- "f6c3855b1c1d3836d7ce903b21dcde67906f916a"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r}
acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2016, 
                    vars = c("NAME", "B01001_001E", "B06002_001E", "B19013_001E", "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r}
acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names. 

```{r}
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E, age = B06002_001E, hh_income = B19013_001E, income = B19301_001E)
```

Print the first rows of the variable `NAME`.

```{r}

print(acs_il['NAME'][1:5,])

```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names. 

```{r}

acs_il_sep <- acs_il %>%
  separate(NAME, into = c("location", "state"), sep = ",") %>%
  mutate(location = gsub(" village", "", location)) %>%
  mutate(location = gsub(" city", "", location)) %>%
  mutate(location = gsub(" town", "", location))
head(acs_il_sep)

```

First, check how many cities don't appear in both data sets, i.e. cannot be matched.

```{r}

acs_il_sep %>%
  anti_join(new_interest_city, by = "location")

```

That's a lot, unfortunately. However, we can still try using the data. Create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets. 

```{r}

joined <- acs_il_sep %>%
  inner_join(new_interest_city, by = "location")
head(joined)

```

Now we can utilize information from both data sources. As an example, print the `crime` and `loans` search popularity for the first ten cities in Illinois with the highest population (in 2016).

```{r}

joined %>%
  arrange(desc(pop)) %>%
  select(location, pop, crime, loans) %>%
  slice(1:10)

```

Next, compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks.

```{r}

joined %>%
  mutate(above_average_house = hh_income > mean(hh_income)) %>%
  group_by(above_average_house) %>%
  na.omit() %>%
  summarise(mean(crime), mean(loans))

```

Is there a relationship between the median household income and the search popularity of `loans`? Plot a scatterplot with `qplot()`.

```{r}

qplot(hh_income, loans, data = joined)

```
There appears to be no relationship between median household income and the search popularity of the word "loans". Many rows were not included due to missing data and several outliers can be seen in the data so more analysis is required to further understand this relationship.